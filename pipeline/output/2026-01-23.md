---
date: 2026-01-23
url: https://theinnermostloop.substack.com/p/a-conversation-with-ray-kurzweil
title: "A Conversation with Ray Kurzweil"
wordcount: 3256
---

# A Conversation with Ray Kurzweil

[Ray Kurzweil](https://en.wikipedia.org/wiki/Ray_Kurzweil) has been a north star for futurists for decades. Below are excerpts from our [recent conversation](https://www.youtube.com/watch?v=8iWSNwIRazc) as part of the “Moonshots” podcast, recorded on January 15, 2026, which have been lightly edited for clarity.

### [On Confirming the Singularity](https://youtu.be/8iWSNwIRazc?t=785)

**AWG:** “Ray, first of all, it’s wonderful to be chatting with you again. Always enjoy our conversations. Let’s talk about the Turing Test. I’ve argued … in the past that the Turing Test went by with a whimper, not a bang. It flew by. [The Loebner Prize](https://en.wikipedia.org/wiki/Loebner_Prize) was cancelled before the Turing Test was arguably passed. And yet, it was passed and there was no celebration.”

**RK:** “The Loebner test was not a really good test. He had various practices that were really not in accord with the Turing Test. And the Turing Test is really matching an ordinary person that’s talking, not really an expert in the field. AGI, I think, is actually a better view because we’re actually matching the best person in each field and we have maybe several thousand -- maybe several hundred thousand -- fields that you could be expert in and AGI means that you can match a human being in any of the fields and then combine the insight into many different fields together, which no human being can do. I mean, Einstein was very good at physics but he actually was interested in playing a violin, but he was not an expert in playing a violin. He was only an expert in physics. People maybe can master two fields at the most, but there are actually thousands of fields and if you could actually be an expert in all of them and then combine all those insights, that’s something that’s quite unique. So that’s what AGI represents, whereas the Turing Test is really matching an ordinary person with a lot of mischaracterizations of different things.”

**AWG:** “I agree that AGI and passing the Turing Test are, for most common definitions, different standards. The question I was going to ask, though, is: arguably, if you agree with the premise that the Turing Test as reasonably defined -- not the original gender-presentation-based Turing Test, but the subsequent definition -- was was passed without very much hoopla at all, do you think the same is going to happen with the Singularity? There’s, in particular, one of my favorite scenes in [Charlie Stross’s novel, ‘Accelerando.](https://www.antipope.org/charlie/blog-static/fiction/accelerando/accelerando.html)’ You have a bunch of characters who’ve been all uploaded to a starwisp traveling to another star system who are all arguing with each other. They’re post-human uploads arguing with each other as to whether the Singularity has even happened. Do you think that’s what’s actually going to happen here, where the Singularity will zoom by, and we’ll all be arguing with each other decades later, ‘Did the singularity even happen? Has it happened yet?’”

**RK:** “I mean, these standards are not very clear. Not everybody agrees that we’ve passed the Turing Test. And when we pass AGI, there’ll be disagreements. It’s disagreements now as to what that means. People say it’s basically as good as somebody who’s a little bit above average intelligence. I define AGI as being an expert in every area when there’s many different areas that you can be expert in. So that’s actually quite an impressive level and I think we’ll get there by 2029. The thing is then you can combine your insights into every possible field. We already have large language models that can answer questions in lots of different fields. No person can do what a large language model can do today, let alone what what’ll happen by 2029.”

### [On Consciousness](https://youtu.be/8iWSNwIRazc?t=1458)

**AWG:** “I’m a proponent, broadly speaking, of AI personhood, and I guess I’ll play the contrarian role that I’m sometimes painted as, of respectfully disagreeing with with my friend Ray that there aren’t benchmarks for AI consciousness. I think there has been over the past 2 years marked progress toward developing quantitative benchmarks for, call it, ‘self-awareness’ rather than ‘consciousness,’ which may be slightly less mushy as a term, including, as I’ve pointed out in the past, [tests for whether certain models can detect overlaid activations in their residual streams](https://www.anthropic.com/research/introspection), if they’re transformers. I see progress toward developing real benchmarks for self-awareness in models.”

**RK:** “Yes, but I’ll give you a something else that’s even more perplexing. There’s lots of conscious people. Now, I can’t prove that that you’re conscious, but I believe that you are. I believe that a human being that acts conscious is probably conscious. But why do I have the consciousness I have? There’s all these conscious beings, but there’s one person that I relate to that, if something happens to it, I care about it in a different way than I care about other people: my own consciousness. So why am I conscious? Why was I born in 1948? Why am I a male on Earth? And why am I not another animal? And so I mean why am I the person that I am? You could think the same thing about yourself, but it’s a subjective view of consciousness. Why am I the person that I am? And that’s really hard to explain. Why do I have all the hallmarks of this particular person?”

**AWG:** “Of course, Ray, it’s such an ironic question that in my mind -- ha! -- you’re asking [an anthropic question](https://en.wikipedia.org/wiki/Anthropic_principle). What you just posed -- ‘why am I myself?’ -- is the most fundamental anthropic -- lowercase ‘A’, not capital ‘A’ -- question that one can ask. And, why does the universe appear the way it does? And the usual answer is: if the universe or your own identity had sufficiently different properties, you wouldn’t be around to ask the question...”

**RK:** “It’s very hard to even ask the question and people don’t actually quite understand it.”

### [On Digital Resurrection](https://youtu.be/8iWSNwIRazc?t=1989)

**AWG:** “I’ll maybe pose hopefully a less obvious question for you, Ray. You’ve been very public about keeping and maintaining lots of documents, lots of artifacts from your father, who I gather was a tremendous influence on your life with the premise that AI is going to enable you to basically computationally reconstruct your father someday, if I’m not misconstruing. There is a related notion that has been called variously [‘quantum archaeology’](https://www.reddit.com/r/QuantumArchaeology/) or [‘Humanity’s Common Task.’](https://grokipedia.com/page/the_common_task) Tsiolkovsky has written or had written extensively about this in the context of [Russian Cosmism](https://en.wikipedia.org/wiki/Russian_cosmism). Question for you: when do we get the ability to computationally resurrect dead human beings with AI?”

**RK:** “Well, I mean, prior to that, we could try to create avatars of ourselves. We did create one of my father. And I’m creating now an avatar of myself. I have actually a lot more material that we can put into text. I have 11 books. I’ve got several hundred articles that I’ve written, articles about me. All of this will go into a large language model. We’ll create something that can talk like me and it will look like me. And I get probably 5 to 10 requests for interviews and podcasts a day. and I can’t do most of them. So, I’ll actually offer them, you can interview the avatar. The avatar is actually better than me because it will remember everything. I don’t remember everything that I’ve said. So the avatar would actually be better and you can interview the avatar as long. You can do it in another language. And that’ll be this year... Now that’s not actually creating everything about me or my father, which we have actually less material of his, although we have enough to create an avatar that’s also lively. Being able to relate everything that a person has and the state of their bodies and so on, that will happen eventually, but that’s probably another, you know, 10 or 15 years away.”

**AWG:** “Do you view that as the killer app of the Singularity, the so-called ‘Common Task’ of resurrecting, computationally with AI, every human who has ever existed?”

**RK:** “That’s one of them, yeah. To me, I’m very interested in being able to achieve longevity escape velocity where a year goes by, you age a year, but you get back that year from advances in medicine that keep you going for another year, or more than a year, so that you don’t actually age during that year, but you’ll actually get it back from advances in medicine and so on.

### [On Cryonics](https://youtu.be/8iWSNwIRazc?t=2838)

**AWG:** “I think you and I probably see the world quite similarly. Rather than having hand-wringing discussions about ‘death with dignity’ and going to Canada, I would argue we should be talking about cryonics as recognizing that [approximately 150,000 people are dying every day in our world](https://consensus.app/home/blog/how-many-people-die-in-a-day-on-average-worldwide/) and not everyone statistically if we get to [Longevity Escape Velocity](https://en.wikipedia.org/wiki/Longevity_escape_velocity) by the early 2030s as you predict that’s many, many millions of people who are going to die between now and LEV. Why do you think more people aren’t obtaining cryonics plans for themselves, and what can you say here -- we have hundreds of thousands of subscribers, hundreds of thousands of viewers -- to encourage viewers to [consider getting cryonics plans for themselves](https://www.alcor.org/membership/pricing-and-dues/) so they don’t have to move to Canada to ‘die with dignity’ if they’re in that position?”

**RK:** “Well, my point on cryonics is that that is Plan D... Plan A, B, and C is to remain alive one way or another. And cryonics, it’s Plan D. I mean, I have enough trouble keeping track of my ideas when I’m able to give arguments for them and keep track of them. It’d be hard to imagine keeping track of them while I’m basically dead. Coming back... I mean I have concerns about it. You may come back and you may not be happy with the way you come back. I mean, cryonics is better than not doing cryonics, because at least you have some chance of coming back, but there’s risks with it, so I’m doing it. Very few people do it. I mean, the number of people who die who elect for cryonics is very, very small. I have done it. I hope it works... But I hope that I won’t need that opportunity...”

**AWG:** “I would say, Ray, it’s unconscionable to me that -- I think you have the statistics -- I think probably a few thousand people (order of magnitude) have cryonics plans. Why do you think it’s not hundreds of millions? And again, is there anything that you would care to do -- you’re speaking to hundreds of thousands of people who take the future of technology very seriously -- to maybe persuade them, if you think this is a righteous act, that they should be perhaps [considering cryonics plans for themselves](https://www.alcor.org/membership/pricing-and-dues/)?”

**RK:** “Perhaps. But given that I have limited persuasion ability on people who listen to me, I would tell people they should do everything they can to stay alive. That’s because the best way of being alive in the future is to stay alive right now. And there’s a lot you can do to remain alive.”

### [On Non-Human Intelligence](https://youtu.be/8iWSNwIRazc?t=3611)

**AWG:** “Ray, obviously, if this isn’t obvious from some of my questions and comments, I’m an enormous fan of both you and your writings and your courageous extrapolation of following the ‘Law of Straight Lines,’ of progress in experience curves, progress in Moore’s Law-type experience curves, your [‘Law of Accelerating Returns,’](https://en.wikipedia.org/wiki/The_Law_of_Accelerating_Returns) your [‘Countdown to the Singularity,’](https://www.singularity.com/images/charts/CountdowntoSingularityLog.jpg) all arguably variants on various forms of [experience curves from economics](https://en.wikipedia.org/wiki/Experience_curve_effect). Question for you: so, if we follow to its logical conclusion your Law of Accelerating Returns and your Countdown to the Singularity, this idea that -- almost in a technologically deterministic way -- we emerge from a primordial soup and everything follows some very nice, elegant Law of Straight Lines-style exponential calendar, do you think that this implies that our universe is abundant with intelligent civilizations? And, if so -- in other words, abundant not just human intelligence, but non-human intelligence as well -- do you think that would then imply that there are [non-human intelligent civilizations on or near Earth](https://www.npr.org/2023/07/27/1190390376/ufo-hearing-non-human-biologics-uaps)?”

**RK:** “The fact that we can emerge as a far more intelligent version of ourselves in a short period of time doesn’t imply that there are intelligences that go beyond humans. We haven’t really seen evidence of that. I mean, there’s a lot of interest in trying to find signals in the universe that would indicate that there is some intelligent source of them. We haven’t actually found that yet, and we have more and more ability to look. So it may exist but we don’t know that there’s any intelligence besides that coming from Earth. And consider the more-and-more ability for us to actually evaluate different types of intelligent sources that are not coming from Earth, and yet we still don’t see any evidence of that. That kind of indicates that they aren’t there. But there’s no way of actually determining that, because we can only look at a very small fraction of what’s out there.”

**AWG:** “Ray, you’ve made many, many predictions of technologies that you think either the Singularity itself or progress toward the Singularity would unlock. Do you think that progress toward the Singularity would answer the question that I think many people most want existentially an answer to, which is, [is humanity alone](https://en.wikipedia.org/wiki/Zoo_hypothesis)?”

**RK:** “Yeah. I mean, so far, if we’re not alone, we’re still pretty lonely because we haven’t come into contact with any intelligent source aside from ourselves. There’s fantastic things happening in the universe and the universe goes on seemingly forever. So it’s certainly possible that we’ll find something and it’s impossible to rule that out, but so far we haven’t actually done that. So we certainly feel alone because there’s nobody else we can point to. We can’t point to some other star system saying, ‘Well, there’s a source coming from that that’s clearly intelligent and we’d like to contact them.’ We can’t even identify a thing like that, so far.”

### [On the Future Physical Form of Intelligence](https://youtu.be/8iWSNwIRazc?t=4534)

**AWG:** “I’d like to shift gears, Ray, and maybe talk about the past and future of the nature of the mind. One of the many striking performances, and I think just incredible accomplishments of yours going all the way back, this is more than 60 years back now, to [your appearance on ‘I’ve Got a Secret’ on television with Steve Allen in February of 1965](https://www.youtube.com/watch?v=X4Neivqp2K4). It’s incredible to think that that was 60-plus years ago. you demonstrated an AI-based music generator on television. I thought that was such...”

**RK:** “Yeah, that was actually the first music composition by AI anywhere...”

**AWG:** “Right, so 60 years ago, you demonstrated what I understand to be the first, at least on-television, AI music generator. I’d like to ask you now, 60 years plus from now -- so we’re now in 2026, so we’re talking 2086 -- what form do you think most intelligence in our Solar System will take? And I’ll offer you a few options and I’ll deny you one option. The option that I’ll deny you is: you’re not allowed to say, ‘It’s past the Singularity so I have no idea.’ I’m going to condition on you having a real opinion on this topic. I’ll offer you a few options and an escape valve for maybe something that I haven’t thought of... So the question is, again, 60 years from now in the year 2086 what form will most intelligence in our Solar System take? A few options. Meatbodies, substantially similar to the way human intelligence is embodied now. That’s option one. Cyborgs, which is some sort of human-machine hybrid, inclusive of nanorobots in the human bloodstream. Uploads, that’s option three, so human minds that have been uploaded to the cloud. Foundation models or pure AIs, not dissimilar to GPT-type models that we have right now. Some sort of unrecognizable life form, maybe an unrecognizable arrangement of matter or energy that’s far more efficient. In the past... I have talked... about how [black holes, for example, are amazing computers in principle](https://www.scientificamerican.com/article/black-hole-computers-2007-04/). So maybe something like that or something totally different, maybe uploads to the gravitational field, or something else entirely. So, I’m laying out a few options plus an escape valve. What do you think?”

**RK:** “I mean, we’re going to have things like computronium by, certainly, by 2045, if not sooner, and I know people that are working on this... So, one analysis has a basically one-liter cube that would be more intelligent than all people, it would be like 10 billion people combined, in one setting. So that’s going to be happening by 2045. So you talk about 2085, it’s going to be after, beyond what we can imagine, but it’ll be even more so. So we’ll be able to create something that’s very exciting. If I listen to, let’s say -- I’ve got some things on the web that go with the book -- my father playing the fifth Brandenburg concerto, which was done several hundred years ago by Bach. And it’s actually quite amazing to listen to that. So it’ll be something like that, only more fantastic, that will generate fantastic emotions, and will be as intelligent as all people combined, or more, so we really can’t imagine what that would be like. But we can state it mathematically by comparing it to the what we can do today.”

**AWG:** “So it sounds, Ray, unless I’m misunderstanding as if you do in fact have a prediction for what most intelligence would look like. Namely if I heard correctly, you think in 60 years most intelligence in the Solar System will be basically software running on [computronium](https://en.wikipedia.org/wiki/Computronium). I think you referenced [some work by Seth Lloyd with the reference to a liter of volume and Seth Lloyd’s work back](https://arxiv.org/abs/quant-ph/9908043), now, 25 years ago on the ultimate computer and the physics of what the physical limit of the maximum amount of computation...”

**RK:** “Since that’s going to be feasible well before 2086, any kind of intelligent being is going to contain that.”

**AWG:** “Yes.”

**RK:** “It’ll be even beyond that but certainly that will be the capability that it will have.”

**AWG:** “Then I have to ask you, I guess, the obvious question. If you think 60 years from now most intelligence in our Solar System is going to be software running on computronium, what happens to our Solar System? Do we [disassemble the planets](https://iopscience.iop.org/article/10.1088/1402-4896/ac9e78)? Do we [starlift our Sun](https://en.wikipedia.org/wiki/Star_lifting)? Do we convert our Solar System to computronium to run the software?”

**RK:** “Yeah. I don’t know. We’ll have to think about that.”

### [On Missed Technological Revolutions](https://youtu.be/8iWSNwIRazc?t=5572)

**AWG:** “The cliche is that [every American male thinks about Ancient Rome at least once per day](https://www.nytimes.com/2023/09/15/style/roman-empire-men-tiktok-instagram.html). So, so here’s my closing cliche question for you... The question, Ray, is: [why didn’t Ancient Rome have an industrial revolution?](https://blog.rootsofprogress.org/why-no-roman-industrial-revolution) And what does the answer to that question teach us about technical revolutions that we could be having today but otherwise aren’t?”

**RK:** “Well, they did have a technical revolution given the capabilities of that time. We can only create things that are feasible, and in keeping with the rate of progress, which was feasible at that time. So, I think they did okay.”
